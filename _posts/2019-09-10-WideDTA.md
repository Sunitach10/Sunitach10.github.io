---
layout: post
title:  "WideDTA:Way to predict Drug-target binding affinity using Convolution Neural Network in Drug Discovery Process-Model2"
date: 2019-09-10
comments: True
mathjax: True
---
<b>**</b> Discovery of potential drugs for new targets is an expensive and time consuming process so we can use deep learning in the pipeline of 
drug-discovery to save the time and cost.<b>**</b>
In previous blog(link………………),I wrote about use of deep learning architecture in identification of drug-target interactions (DTI) strength
(binding affinity) using character-based sequence representation approach.

The successful identification of drug–target interactions (DTI) is a critical step in drug discovery. 
As the field of drug discovery expands with the discovery of new drugs, repurposing of existing drugs and identification of novel 
interacting partners for approved drugs is also gaining interest.

The protein–ligand interactions assume a continuum of binding strength values, also called binding affinity and we are predicting this
value using <b>deep learning architectures</b>.Furthermore, a regression-based model brings in the advantage of predicting an approximate 
value for the strength of the interaction between the drug and target which in turn would be significantly beneficial for limiting the 
large compound search-space in drug discovery studies.

In this model, I used the word-based sequence representation. it is a promising alternative to the character-based sequence representation
approach (previous blog)in deep learning models for binding affinity prediction.

<b>Dataset and Data Preprocessing-</b> We evaluated our model on the KIBA data set (kinase inhibitors bioactive data).We used the filtered version of the KIBA dataset, in which each protein and ligand has at least ten interactions. KIBA set contains ligands-2111, and proteins-229.

In this we have different lengths of proteins and ligands ,But we considered ligand have sequence length 50(characters) and for every protein sequence is 600(characters)number of proteins and ligands reduced this is easy to run in my CPU.If We have GPU we can take max length to consider more number of proteins and ligands.

Here, we used three different text-based information sources to model. In previous blog work showed that the use of protein sequence and ligand SMILES is an effective approach to model the interactions between these entities .In this work, we explored the effect of adding additional specific information, namely domain/motif information for the proteins , which might contribute to a better modeling of the interactions.

The input to the model is-three seq. LS,PS,PDM

<b> Protein Sequence (PS) -</b> The protein sequence is composed of 20 different types of amino acids. We first collected the sequences of the respective proteins for each dataset and then, extracted 3-residue words from the sequences. For instance, an example protein Kinase SGK1 (UniProt, O00141) with the sequence of "MTVKTEAAKGTLTYSRMRGMVA……YAPPTDSFL" is represented with the following set of words { 'MTV', 'KTE', …, 'TDS', 'TVK', 'TEA', …, 'DSF', 'VKT', 'EAA', …, 'SFL'}.

<b> Protein Domains and Motifs (PDM) - </b> <b>PROSITE  </b> is database that serves as a resource for motif and profile descriptors of the proteins . Multiple sequence alignment of protein sequences reveals that specific regions within the protein sequence are more conserved than others, and these regions are usually important for folding, binding, catalytic activity or thermodynamics. These subsequences are called either motifs or profiles. A motif is a short sequence of amino-acids (usually 10–30 ), while profiles provide a quantitative measure of sequences based on the amino-acids they contain. Profiles are better at detection of domains and families. For instance, Kinase SGK1 (UniProt, O00141) has the ATP-binding motif 'IGKGSFGKVLLARHKAEEVFYAVKVLQKKAILK', while the Protein Kinase Domain profile is about seven times longer than the motif. We used the PROSITE database to extract motifs and profiles for each respective protein in our datasets. We then extracted 3-residue subsequences from each motif and domain similarly to the approach adopted in PS.



